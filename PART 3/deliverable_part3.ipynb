{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\Users\\Usuario\\anaconda\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "import time\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the next lines to run on Google Colab, please.\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_PATH = '../data/Rus_Ukr_war_data.json'\n",
    "MAPPING_PATH = '../data/Rus_Ukr_war_data_ids.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and modules\n",
    "\n",
    "### Data cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_json_to_dataframe(doc_path = '../data/Rus_Ukr_war_data.json'):\n",
    "    #with open(doc_path) as fp:\n",
    "    #    lines = fp.readlines()\n",
    "    df=pd.read_json(doc_path, lines=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_raw_dataset(raw_df):\n",
    "    # Select only relevant columns\n",
    "    clean_df = raw_df[[\"created_at\",\"id\",\"full_text\",\"entities\",\"favorite_count\",\"retweet_count\",\"user\"]]\n",
    "\n",
    "    # Rename columns\n",
    "    renames = {\"created_at\":\"date\", \"full_text\":\"tweet\", \"favorite_count\":\"likes\",\"retweet_count\":\"retweets\", \"id\":\"tweet_id\"}\n",
    "    clean_df = clean_df.rename(columns=renames)\n",
    "\n",
    "    # Create Series of list of hashtags from `entities` object\n",
    "    df_hashtags = pd.json_normalize(clean_df[\"entities\"])[\"hashtags\"]\n",
    "    df_hashtags = df_hashtags.apply(lambda x: [item[\"text\"] for item in x])\n",
    "\n",
    "    # Create Series of username ids\n",
    "    df_user = pd.json_normalize(clean_df[\"user\"])[\"id\"].rename(\"user_id\")\n",
    "    df_username = pd.json_normalize(clean_df[\"user\"])[\"screen_name\"].rename(\"username\")\n",
    "\n",
    "    # Merge hashtags and username columns to the DataFrame\n",
    "    clean_df = pd.concat([clean_df,df_hashtags,df_user, df_username], axis=1).drop(columns=[\"entities\",\"user\"])\n",
    "\n",
    "    # Create URL column manually from the user id and tweet id columns\n",
    "    clean_df[\"url\"] = \"https://twitter.com/\" + clean_df[\"user_id\"].astype(str) + \"/status/\" + clean_df[\"tweet_id\"].astype(str)\n",
    "\n",
    "    # Extract tags to other users from the tweet body\n",
    "    clean_df[\"tags\"] = clean_df[\"tweet\"].apply(lambda x: re.findall(r\"@(\\w+)\", x))\n",
    "\n",
    "    # Returns a DataFrame of tweets with columns [\"date\", \"tweet_id\", \"tweet\", \"likes\", \"retweets\", \"hashtags\", \"user_id\", \"url\", \"tags\", \"tags\"]\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "def remove_emojis(tweet):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emojis\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictograms\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # Flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    return emoji_pattern.sub(r'', tweet)\n",
    "\n",
    "\n",
    "def clean_tweet(line):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    ## START CODE\n",
    "    line = re.sub(r'[.,;:!?\"\\'-@]', '', line).replace(\"#\", \"\").replace(\"‚Äô\", \"\").replace(\"‚Äú\", \"\").replace(\"\\n\",\" \")\n",
    "    line =  line.lower() ## Transform in lowercase\n",
    "    line = remove_emojis(line).strip().replace(\"  \", \" \")\n",
    "    line = line.split(\" \") ## Tokenize the text to get a list of terms\n",
    "    line =[word for word in line if word not in stop_words]  ## eliminate the stopwords (HINT: use List Comprehension)\n",
    "    line =[stemmer.stem(word) for word in line] ## perform stemming (HINT: use List Comprehension)\n",
    "    line = [word for word in line if word != \"\"]\n",
    "    ## END CODE\n",
    "    \n",
    "    return line\n",
    "\n",
    "\n",
    "def process_text_column(column):\n",
    "    column = column.apply(clean_tweet)\n",
    "    return column\n",
    "\n",
    "def join_docs_tweets_dfs(tweets, csv_file='../data/Rus_Ukr_war_data_ids.csv'):\n",
    "    docs = pd.read_csv(csv_file, sep=\"\\t\", header=None)\n",
    "    docs = docs.rename(columns={0:\"doc_id\",1:\"tweet_id\"})\n",
    "    tweets = tweets.join(docs.set_index('tweet_id'), on='tweet_id')\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search engine models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdfIndex():\n",
    "\n",
    "    def __init__(self, ids, stemmed_text, num_documents):\n",
    "        \n",
    "        self.index = defaultdict(list)\n",
    "        self.tf = defaultdict(list)\n",
    "        self.df = defaultdict(int)\n",
    "        self.idf = defaultdict(float)\n",
    "\n",
    "        stemmed_text = stemmed_text.tolist()\n",
    "        ids = ids.tolist()\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "\n",
    "            tweet = stemmed_text[i]\n",
    "            tweet_id = ids[i]\n",
    "\n",
    "            terms = [word for word in tweet]\n",
    "            page_id = int(tweet_id)\n",
    "\n",
    "            current_page_index = {}\n",
    "\n",
    "            for position, term in enumerate(terms):\n",
    "                try:\n",
    "                    current_page_index[term][1].append(position)\n",
    "                except:\n",
    "                    current_page_index[term] = [page_id, array('I', [position])]\n",
    "\n",
    "            norm = 0\n",
    "            for term, posting in current_page_index.items():\n",
    "                norm += len(posting[1]) ** 2\n",
    "            norm = math.sqrt(norm)\n",
    "\n",
    "            for term, posting in current_page_index.items():\n",
    "                self.tf[term].append(np.round(len(posting[1]) / norm, 4))\n",
    "                self.df[term] += 1\n",
    "\n",
    "            for term_page, posting_page in current_page_index.items():\n",
    "                self.index[term_page].append(posting_page)\n",
    "\n",
    "            for term in self.df:\n",
    "                self.idf[term] = np.round(np.log(float(num_documents / self.df[term])), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdfRanking():\n",
    "\n",
    "    def __init__(self, index):\n",
    "        self.index = index.index\n",
    "        self.tf = index.tf\n",
    "        self.df = index.df\n",
    "        self.idf = index.idf\n",
    "\n",
    "    def rank(self, stemmed_query, unranked_results):\n",
    "                                          \n",
    "        doc_vectors = defaultdict(lambda: [0] * len(stemmed_query))\n",
    "        query_vector = [0] * len(stemmed_query)\n",
    "\n",
    "        query_terms_count = collections.Counter(stemmed_query)\n",
    "\n",
    "        query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "        for termIndex, term in enumerate(stemmed_query):\n",
    "            if term not in self.index:\n",
    "                continue\n",
    "            query_vector[termIndex] = query_terms_count[term] / query_norm * self.idf[term]\n",
    "\n",
    "            for doc_index, (doc, postings) in enumerate(self.index[term]):\n",
    "\n",
    "                if doc in unranked_results:\n",
    "                    doc_vectors[doc][termIndex] = self.tf[term][doc_index] * self.idf[term] \n",
    "\n",
    "        doc_scores = [[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items()]\n",
    "        doc_scores.sort(reverse=True)\n",
    "        result_docs = [x[1] for x in doc_scores]\n",
    "\n",
    "        return result_docs\n",
    "                                          \n",
    "    def search(self, query):\n",
    "\n",
    "        query = clean_tweet(query)\n",
    "        docs = set()\n",
    "        for term in query:\n",
    "            try:\n",
    "                # store in term_docs the ids of the docs that contain \"term\"\n",
    "                term_docs = set([posting[0] for posting in self.index[term]])\n",
    "                                          \n",
    "                # retain all documents which contain all words from the query\n",
    "                if len(docs)==0:\n",
    "                    docs = term_docs\n",
    "                else:\n",
    "                    docs = docs.intersection(term_docs)\n",
    "            except:\n",
    "                #term is not in index\n",
    "                pass\n",
    "            \n",
    "        docs = list(docs) #docs are the unranked results\n",
    "                                          \n",
    "        ranked_docs = self.rank(query, docs)\n",
    "\n",
    "        return ranked_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our score will be computed as follows:\n",
    "\n",
    "$$\n",
    "\\text{Our score} = \\frac{1}{4} \\text{likes} + \\frac{3}{4} \\text{retweets}\n",
    "$$\n",
    "\n",
    "Where $\\text{likes}$ and $\\text{retweets}$ are normalized from $0$ to $1$, and in logarithmic scale, as in the EDA in Part 1 we saw that there were a lot of tweets with few likes and retweets and very few tweets with a lot of likes and retweets.\n",
    "\n",
    "We gave different weights to the number of likes and the number of retweets because we considered that, in Twitter, retweets are more representative of the popularity of a tweet because when retweeting a tweet, it appears in your feed so that your community also interacts with the tweet. On the other hand, liking a tweet only represents the fact that you agree or enjoy the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurScore():\n",
    "\n",
    "    def __init__(self, index, our_score, alpha=0.5):\n",
    "        \n",
    "        self.index = index.index\n",
    "        self.tf = index.tf\n",
    "        self.df = index.df\n",
    "        self.idf = index.idf\n",
    "        self.our_score = our_score\n",
    "        self.alpha = alpha\n",
    "\n",
    "\n",
    "    def rank(self, stemmed_query, unranked_results):\n",
    "                                          \n",
    "        doc_vectors = defaultdict(lambda: [0] * len(stemmed_query))\n",
    "        query_vector = [0] * len(stemmed_query)\n",
    "\n",
    "        query_terms_count = collections.Counter(stemmed_query)\n",
    "\n",
    "        query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "        for termIndex, term in enumerate(stemmed_query):\n",
    "            if term not in self.index:\n",
    "                continue\n",
    "            query_vector[termIndex] = query_terms_count[term] / query_norm * self.idf[term]\n",
    "\n",
    "            for doc_index, (doc, postings) in enumerate(self.index[term]):\n",
    "\n",
    "                if doc in unranked_results:\n",
    "                    doc_vectors[doc][termIndex] = self.tf[term][doc_index] * self.idf[term] \n",
    "\n",
    "        doc_scores = [[(1-self.alpha) * np.dot(curDocVec, query_vector) +\n",
    "                       self.alpha * self.our_score[self.our_score[\"tweet_id\"]==doc][\"score\"].item(), doc] for doc, curDocVec in doc_vectors.items()]\n",
    "        doc_scores.sort(reverse=True)\n",
    "        result_docs = [x[1] for x in doc_scores]\n",
    "\n",
    "        return result_docs\n",
    "                                          \n",
    "    def search(self, query):\n",
    "\n",
    "        query = clean_tweet(query)\n",
    "        docs = set()\n",
    "        for term in query:\n",
    "            try:\n",
    "                # store in term_docs the ids of the docs that contain \"term\"\n",
    "                term_docs = set([posting[0] for posting in self.index[term]])\n",
    "                                          \n",
    "                # retain all documents which contain all words from the query\n",
    "                if len(docs)==0:\n",
    "                    docs = term_docs\n",
    "                else:\n",
    "                    docs = docs.intersection(term_docs)\n",
    "            except:\n",
    "                #term is not in index\n",
    "                pass\n",
    "            \n",
    "        docs = list(docs) #docs are the unranked results\n",
    "                                          \n",
    "        ranked_docs = self.rank(query, docs)\n",
    "\n",
    "        return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_our_score (clean_df):\n",
    "\n",
    "    tweet_ids = clean_df[\"tweet_id\"]\n",
    "\n",
    "    # LOG-SCALE AND NORMALIZE 0-1\n",
    "    likes = np.log(clean_df[\"likes\"].apply(lambda x: x + 1))\n",
    "    likes = (likes - np.min(likes)) / (np.max(likes) - np.min(likes))\n",
    "\n",
    "    retweets = np.log(clean_df[\"retweets\"].apply(lambda x: x + 1))\n",
    "    retweets = (retweets - np.min(retweets)) / (np.max(retweets) - np.min(retweets))\n",
    "\n",
    "    # COMPUTE USING OUR FORMULA\n",
    "    our_score = likes.apply(lambda x: x*0.25) + likes.apply(lambda x: x*0.75)\n",
    "\n",
    "    # RETURN DATAFRAME OF TWEET IDS AND SCORES\n",
    "    return pd.DataFrame({\"tweet_id\": tweet_ids, \"score\": our_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Tweets in the corpus: 4000\n"
     ]
    }
   ],
   "source": [
    "# Import from JSON file\n",
    "raw_df = from_json_to_dataframe(DOC_PATH)\n",
    "\n",
    "# Clean raw DataFrame to have a more convenient structure\n",
    "clean_df = clean_raw_dataset(raw_df)\n",
    "\n",
    "# Stem tweets\n",
    "clean_df[\"stemmed_tweet\"] = process_text_column(clean_df[\"tweet\"])\n",
    "\n",
    "# Join with map csv\n",
    "clean_df = join_docs_tweets_dfs(clean_df, MAPPING_PATH)\n",
    "\n",
    "\n",
    "print(\"Total number of Tweets in the corpus: {}\".format(len(clean_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>url</th>\n",
       "      <th>tags</th>\n",
       "      <th>stemmed_tweet</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-30 18:39:17+00:00</td>\n",
       "      <td>1575918221013979136</td>\n",
       "      <td>@MelSimmonsFCDO Wrong. Dictator Putin's Fascis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[RussiainvadesUkraine, UkraineRussiaWar]</td>\n",
       "      <td>1404526426330701825</td>\n",
       "      <td>LynBank25442089</td>\n",
       "      <td>https://twitter.com/1404526426330701825/status...</td>\n",
       "      <td>[MelSimmonsFCDO]</td>\n",
       "      <td>[melsimmonsfcdo, wrong, dictat, putin, fascist...</td>\n",
       "      <td>doc_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-30 18:38:44+00:00</td>\n",
       "      <td>1575918081461080065</td>\n",
       "      <td>üá∫üá¶‚ù§Ô∏è The Armed Forces liberated the village of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Drobysheve, Lymansk, Donetsk, UkraineRussiaWa...</td>\n",
       "      <td>1257116113898536961</td>\n",
       "      <td>Feher_Junior</td>\n",
       "      <td>https://twitter.com/1257116113898536961/status...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[arm, forc, liber, villag, drobyshev, lymansk,...</td>\n",
       "      <td>doc_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-30 18:38:23+00:00</td>\n",
       "      <td>1575917992390823936</td>\n",
       "      <td>ALERT üö®Poland preps anti-radiation tablets ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[NATO, Putin, Russia, RussiaInvadedUkraine, Uk...</td>\n",
       "      <td>1460003892415053828</td>\n",
       "      <td>NEWS_ALL_TIME</td>\n",
       "      <td>https://twitter.com/1460003892415053828/status...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[alert, poland, prep, antiradi, tablet, nuclea...</td>\n",
       "      <td>doc_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date             tweet_id  \\\n",
       "0 2022-09-30 18:39:17+00:00  1575918221013979136   \n",
       "1 2022-09-30 18:38:44+00:00  1575918081461080065   \n",
       "2 2022-09-30 18:38:23+00:00  1575917992390823936   \n",
       "\n",
       "                                               tweet  likes  retweets  \\\n",
       "0  @MelSimmonsFCDO Wrong. Dictator Putin's Fascis...      0         0   \n",
       "1  üá∫üá¶‚ù§Ô∏è The Armed Forces liberated the village of...      0         0   \n",
       "2  ALERT üö®Poland preps anti-radiation tablets ove...      0         0   \n",
       "\n",
       "                                            hashtags              user_id  \\\n",
       "0           [RussiainvadesUkraine, UkraineRussiaWar]  1404526426330701825   \n",
       "1  [Drobysheve, Lymansk, Donetsk, UkraineRussiaWa...  1257116113898536961   \n",
       "2  [NATO, Putin, Russia, RussiaInvadedUkraine, Uk...  1460003892415053828   \n",
       "\n",
       "          username                                                url  \\\n",
       "0  LynBank25442089  https://twitter.com/1404526426330701825/status...   \n",
       "1     Feher_Junior  https://twitter.com/1257116113898536961/status...   \n",
       "2    NEWS_ALL_TIME  https://twitter.com/1460003892415053828/status...   \n",
       "\n",
       "               tags                                      stemmed_tweet doc_id  \n",
       "0  [MelSimmonsFCDO]  [melsimmonsfcdo, wrong, dictat, putin, fascist...  doc_1  \n",
       "1                []  [arm, forc, liber, villag, drobyshev, lymansk,...  doc_2  \n",
       "2                []  [alert, poland, prep, antiradi, tablet, nuclea...  doc_3  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   date           4000 non-null   datetime64[ns, UTC]\n",
      " 1   tweet_id       4000 non-null   int64              \n",
      " 2   tweet          4000 non-null   object             \n",
      " 3   likes          4000 non-null   int64              \n",
      " 4   retweets       4000 non-null   int64              \n",
      " 5   hashtags       4000 non-null   object             \n",
      " 6   user_id        4000 non-null   int64              \n",
      " 7   username       4000 non-null   object             \n",
      " 8   url            4000 non-null   object             \n",
      " 9   tags           4000 non-null   object             \n",
      " 10  stemmed_tweet  4000 non-null   object             \n",
      " 11  doc_id         4000 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(4), object(7)\n",
      "memory usage: 375.1+ KB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Comparing TFIDF+Cos vs. TFIDF+OurScore+Cos ranking methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = TfIdfIndex(ids=clean_df[\"tweet_id\"], stemmed_text = clean_df[\"stemmed_tweet\"], num_documents=len(clean_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_ranking = TfIdfRanking(index = index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_score = compute_our_score(clean_df)\n",
    "our_score_ranking = OurScore(index=index, our_score=our_score, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: tank Kharkiv\n",
      "\n",
      "======================\n",
      "Sample of 10 results out of 27 for the searched query:\n",
      "\n",
      "tweet_id = 1575739143748927488\n",
      "author = @2536luis\n",
      "likes = 2\n",
      "retweets = 0\n",
      "tweet = Ukrainian tank holds the ground against two advancing russian tanks.\n",
      "\n",
      "Unfortunately, the Ukrainian tank takes a fatal hit\n",
      "\n",
      "#Ukraine #UkraineRussiaCrisis #WarCrimes #UkraineRussiaWar #Kyiv #Mariupol #Chernihiv #Lviv #Kharkiv #Melitopol #Irpin #Bucha #Borodyanka #Odesa #Crimea https://t.co/cYGjgmoeLP\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575528927245770752\n",
      "author = @Chronology22\n",
      "likes = 0\n",
      "retweets = 0\n",
      "tweet = Destroyed Ukrainian tank in the Kharkiv region.\n",
      "\n",
      "#Ukraine #Ukrainewar #UkraineRussiaWar #Kharkiv https://t.co/xt4JVrWchP\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575435463682363392\n",
      "author = @UkrainianNews24\n",
      "likes = 119\n",
      "retweets = 19\n",
      "tweet = In the Kharkiv region, the air reconnaissance of the State Border Service eliminated a tank, a Tigr armored vehicle and two trucks\n",
      "#UkraineRussiaWar https://t.co/T5j1LSXGDt\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575187749447307265\n",
      "author = @Shadi_Alkasim\n",
      "likes = 2\n",
      "retweets = 0\n",
      "tweet = Soldiers of the Ukrainian army seizing a Russian tank in the #Kharkiv region \n",
      "\n",
      "#Ukraine-#UkraineRussianWar -#UkraineWar -#UkraineRussiaWar-#Russian https://t.co/7zqjb8cYCE\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575196507770593282\n",
      "author = @Seth_Mythrax\n",
      "likes = 6\n",
      "retweets = 0\n",
      "tweet = Another 2 abandoned T-80BV tanks were found in #Kharkiv Oblast! But it was a \"scheduled exit without equipment\" ü§£ü§£ü§£\n",
      "\n",
      " #RussiaUkraineWar #Russia #UkraineRussianWar #UkraineRussiaWar #UkraineWar #UkrainianArmy #Ukraine #Kherson #Donbass #odessa #Kyiv #Kharkiv #NATO #USA https://t.co/rzR3UM16Xn\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575893901080027142\n",
      "author = @war_news247\n",
      "likes = 3\n",
      "retweets = 0\n",
      "tweet = üá∫üá¶ üá∑üá∫   \n",
      "Russian Tank Crushed By ATGM\n",
      "surprisingly some of the crew survived\n",
      "\n",
      "#Ukraine #Russia #war #putin  #kharkiv #UkraineRussiaWar  #kyiv #NATO https://t.co/GfKWmdkyvV\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575834054905462784\n",
      "author = @infussambas\n",
      "likes = 19\n",
      "retweets = 4\n",
      "tweet = üëèFootage of a Russian tank being knocked out by Ukrainian forces in Ol'hivka, Kharkiv Oblast.\n",
      "#Russian #Russia #Ukraine #Ukrainian #UkraineWar #UkraineRussiaWar #RussiaIsATerroristStateR https://t.co/YMADdnvXWQ\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575610720322211840\n",
      "author = @FastStrikeCraft\n",
      "likes = 3\n",
      "retweets = 1\n",
      "tweet = #RussianArmy #Ukraine #Kharkiv  #UkraineRussiaWar #PutinsWar #UkraineWar  #Putin #Donetsk #RussiaInvadedUkraine #KhersonisUkraine   #UkraineWillWin #PutinWarCriminal \n",
      "Ukrainian soldiers pose in front of a destroyed Russian Army T-72B3 main battle tank, in Kharkiv oblast. https://t.co/nwtiBkVKM2\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575600820229242880\n",
      "author = @FastStrikeCraft\n",
      "likes = 2\n",
      "retweets = 1\n",
      "tweet = #RussianArmy #Ukraine #Kharkiv  #UkraineRussiaWar #PutinsWar #UkraineWar  #Putin #Donetsk #RussiaInvadedUkraine   #UkraineWillWin #PutinWarCriminal \n",
      "Ukrainian forces find two more abandoned Russian Army main battle tanks in Kharkiv oblast.\n",
      "One is a T-80BV, the other a T-80U https://t.co/4kV8Gu7ZaU\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575481729535463424\n",
      "author = @TuliosportsINC\n",
      "likes = 30\n",
      "retweets = 6\n",
      "tweet = In a School in recently liberated village in the #Kherson region, retreating #Russian Troops left a Tank and other weapons cache for the #Ukrainian forces. Goodwill. \n",
      "\n",
      "#UkraineRussiaWar #Breaking #Ukraine #ukraineinvasion #SlavaUkra√Øni #bbcnews #Lyman #tvcnewsng #Kharkiv #AP https://t.co/szXdU79hgD\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"tank Kharkiv\"\n",
    "print(\"Query:\", query)\n",
    "results = our_score_ranking.search(query)\n",
    "top = 10\n",
    "\n",
    "print(\"\\n======================\\nSample of {} results out of {} for the searched query:\\n\".format(top, len(results)))\n",
    "for d_id in results[:top]:\n",
    "    tweet = clean_df[clean_df[\"tweet_id\"]==d_id]\n",
    "    print(\"tweet_id = {}\\nauthor = @{}\\nlikes = {}\\nretweets = {}\\ntweet = {}\".format(d_id, tweet[\"username\"].item(), tweet[\"likes\"].item(), tweet[\"retweets\"].item(), tweet[\"tweet\"].item()))\n",
    "    print(\"\\n\\n-------------------------------------------------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert your query:\n",
      "\n",
      "TFIDF result: 1575739143748927488 | OURSCORE result: 1575739143748927488, POPULARITY: 0.13 | MATCH IN SAME POSITION: True\n",
      "TFIDF result: 1575528927245770752 | OURSCORE result: 1575528927245770752, POPULARITY: 0.0 | MATCH IN SAME POSITION: True\n",
      "TFIDF result: 1575187749447307265 | OURSCORE result: 1575435463682363392, POPULARITY: 0.58 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575893901080027142 | OURSCORE result: 1575187749447307265, POPULARITY: 0.13 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575435463682363392 | OURSCORE result: 1575196507770593282, POPULARITY: 0.24 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575610720322211840 | OURSCORE result: 1575893901080027142, POPULARITY: 0.17 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575600820229242880 | OURSCORE result: 1575834054905462784, POPULARITY: 0.36 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575196507770593282 | OURSCORE result: 1575610720322211840, POPULARITY: 0.17 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575889650471665665 | OURSCORE result: 1575600820229242880, POPULARITY: 0.13 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575834054905462784 | OURSCORE result: 1575481729535463424, POPULARITY: 0.42 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575697002331246592 | OURSCORE result: 1575446917198540803, POPULARITY: 0.37 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575462465038872577 | OURSCORE result: 1575697002331246592, POPULARITY: 0.3 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575446917198540803 | OURSCORE result: 1575462465038872577, POPULARITY: 0.27 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575180535890325504 | OURSCORE result: 1575889650471665665, POPULARITY: 0.13 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575481729535463424 | OURSCORE result: 1575180535890325504, POPULARITY: 0.27 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575263742891552768 | OURSCORE result: 1575263742891552768, POPULARITY: 0.08 | MATCH IN SAME POSITION: True\n",
      "TFIDF result: 1575204591469150210 | OURSCORE result: 1575546498145984513, POPULARITY: 0.08 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575546498145984513 | OURSCORE result: 1575457761189679106, POPULARITY: 0.08 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575204441770594304 | OURSCORE result: 1575204591469150210, POPULARITY: 0.0 | MATCH IN SAME POSITION: False\n",
      "TFIDF result: 1575642072295489536 | OURSCORE result: 1575215511235096576, POPULARITY: 0.17 | MATCH IN SAME POSITION: False\n",
      "\n",
      "There are 3/20 tweets in the same position using the two methods.\n",
      "There are 18/20 tweets in common (without considering position) using the two methods.\n"
     ]
    }
   ],
   "source": [
    "print(\"Insert your query:\\n\")\n",
    "query = \"tank Kharkiv\"\n",
    "\n",
    "results_tfidf = tfidf_ranking.search(query)\n",
    "results_ourscore = our_score_ranking.search(query)\n",
    "\n",
    "k = 20\n",
    "\n",
    "matches = 0\n",
    "results_tfidf_top_k = []\n",
    "results_ourscore_top_k = []\n",
    "\n",
    "for i in range(min(len(results_tfidf), k)):\n",
    "    print(f\"TFIDF result: {results_tfidf[i]} | OURSCORE result: {results_ourscore[i]}, POPULARITY: {round(our_score[our_score['tweet_id']==results_ourscore[i]]['score'].item(),2)} | MATCH IN SAME POSITION: {results_tfidf[i]==results_ourscore[i]}\")\n",
    "    if results_tfidf[i] == results_ourscore[i]:\n",
    "        matches += 1\n",
    "    results_tfidf_top_k.append(results_tfidf[i])\n",
    "    results_ourscore_top_k.append(results_ourscore[i])\n",
    "\n",
    "print(\"\")\n",
    "print(\"There are\", str(matches)+\"/\"+str(k), \"tweets in the same position using the two methods.\")\n",
    "print(\"There are\", str(len(set(results_tfidf_top_k).intersection(set(results_ourscore_top_k))))+\"/\"+str(k), \"tweets in common (without considering position) using the two methods.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Word2Vec + cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY1 = \"tank Kharkiv\" # What is the discussion regarding a tank in Kharkiv?\n",
    "QUERY2 = \"nord stream\" # What discussion are there about the Nord Stream pipeline?\n",
    "QUERY3 = \"territories annexation russia\" # What is being said about the annexation of territories in Russia?\n",
    "\n",
    "QUERY4 = \"refugees\" # Are there discussions about the Ukranian refugees?\n",
    "QUERY5 = \"kill putin\" # Are there discussions or messages about killing president Putin or Putin killing people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecCosineSim():\n",
    "\n",
    "    def __init__(self, index, ids, stemmed_text, word2vec_model):\n",
    "        \n",
    "        self.index = index.index\n",
    "        self.tf = index.tf\n",
    "        self.df = index.df\n",
    "        self.idf = index.idf\n",
    "        self.word2vec_model = word2vec_model\n",
    "        self.collection = dict(zip(ids, stemmed_text))\n",
    "\n",
    "    def model(self, text):\n",
    "        \n",
    "        tweet_vectors = []\n",
    "\n",
    "        for word in text:\n",
    "            tweet_vectors.append(self.word2vec_model.wv[word])\n",
    "\n",
    "        return np.average(tweet_vectors, axis=0) # Computes the average of all the tweet vectors\n",
    "\n",
    "\n",
    "    def rank(self, stemmed_query, unranked_results):\n",
    "                                          \n",
    "        doc_vectors = defaultdict(lambda: [0] * len(stemmed_query))\n",
    "        query_vector = self.model(stemmed_query)\n",
    "\n",
    "        for doc in unranked_results:\n",
    "            doc_vectors[doc] = self.model(self.collection[doc])\n",
    "\n",
    "        doc_scores = [[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items()]\n",
    "        doc_scores.sort(reverse=True)\n",
    "        result_docs = [x[1] for x in doc_scores]\n",
    "\n",
    "        return result_docs\n",
    "                                          \n",
    "    def search(self, query):\n",
    "\n",
    "        query = clean_tweet(query)\n",
    "        docs = set()\n",
    "        for term in query:\n",
    "            try:\n",
    "                # store in term_docs the ids of the docs that contain \"term\"\n",
    "                term_docs = set([posting[0] for posting in self.index[term]])\n",
    "                                          \n",
    "                # retain all documents which contain all words from the query\n",
    "                if len(docs)==0:\n",
    "                    docs = term_docs\n",
    "                else:\n",
    "                    docs = docs.intersection(term_docs)\n",
    "            except:\n",
    "                #term is not in index\n",
    "                pass\n",
    "            \n",
    "        docs = list(docs) #docs are the unranked results\n",
    "                                          \n",
    "        ranked_docs = self.rank(query, docs)\n",
    "\n",
    "        return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 300\n",
    "\n",
    "# Depending on the version of the Gensim library, the parameter size is written as size, or vector_size\n",
    "try:\n",
    "    model = Word2Vec(sentences=clean_df[\"stemmed_tweet\"], size=vector_size, window=5, min_count=1, workers=4)\n",
    "except:\n",
    "    model = Word2Vec(sentences=clean_df[\"stemmed_tweet\"], vector_size=vector_size, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_score_index = Word2VecCosineSim(index=index, ids=clean_df[\"tweet_id\"], stemmed_text=clean_df[\"stemmed_tweet\"], word2vec_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: tank Kharkiv\n",
      "\n",
      "======================\n",
      "Sample of 10 results out of 27 for the searched query:\n",
      "\n",
      "tweet_id = 1575528927245770752\n",
      "tweet = Destroyed Ukrainian tank in the Kharkiv region.\n",
      "\n",
      "#Ukraine #Ukrainewar #UkraineRussiaWar #Kharkiv https://t.co/xt4JVrWchP\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575642072295489536\n",
      "tweet = #Russia #Ukraine #RussianArmy \n",
      "Why the Russian ü™ñ Army T-72 Tank is Worse Than You Think\n",
      "\n",
      "#Putin #Russian #RussiaUkraineWar #Russie #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #Kherson #RussianMobilization #USA #Russians #NATO\n",
      "https://t.co/XZU7FObkVS\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575457761189679106\n",
      "tweet = #Russia #Ukraine #RussianArmy \n",
      "Why the Russian ü™ñ Army T-72 Tank is Worse Than You Think\n",
      "\n",
      "#Putin #Russian #RussiaUkraineWar #Russie #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #Kherson #RussianMobilization #USA #Russians #NATO\n",
      "https://t.co/XZU7FNTK4k\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575482368630353920\n",
      "tweet = \"#Russia #Ukraine #RussianArmy \n",
      "Why the Russian ü™ñ Army T-72 Tank is Worse Than You Think\n",
      "\n",
      "#Putin #Russian #RussiaUkraineWar #Russie #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #Kherson #RussianMobilization #USA #Russians #NATO\n",
      "https://t.co/XZU7FNUhTS\"\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575204441770594304\n",
      "tweet = \"Video‚ñ∂Ô∏èWhy the Russian ü™ñ Army T-72 Tank is Worse Than You Think.\n",
      "#Russia #Ukraine #Putin #Russian #Russie #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #Kherson #RussianMobilization #USA #Russians #NATO\n",
      "https://t.co/XZU7FNUhTS\n",
      "\"\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575822033253867521\n",
      "tweet = #Russia #Ukraine #Europe \n",
      "Why The West Hesitant To Supply Modern Tanks Like M1 Abrams\\Leopard To Ukraine\n",
      "Ukraine #NATO Video Archive\n",
      "\n",
      "#Putin #RussianMobilization #Russian #Russie #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #USA\n",
      "https://t.co/S1Z4YOWT3k\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575642464685170688\n",
      "tweet = #Russia #Ukraine #Europe \n",
      "Why The West Hesitant To Supply Modern Tanks Like M1 Abrams\\Leopard To Ukraine\n",
      "Ukraine #NATO Video Archive.\n",
      "\n",
      "#Putin #RussianMobilization #Russian #Russie #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #USA\n",
      "https://t.co/S1Z4YOWT3k\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575482082985660422\n",
      "tweet = #Russia #Ukraine #Europe \n",
      "Why The West Hesitant To Supply Modern Tanks Like M1 Abrams\\Leopard To Ukraine\n",
      "Ukraine #NATO Video Archive\n",
      "\n",
      "#Putin #RussianMobilization #Russian #Russie #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #USA\n",
      "https://t.co/S1Z4YOFQ1k\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575458070381092866\n",
      "tweet = #Russia #Ukraine #Europe \n",
      "Why The West Hesitant To Supply Modern Tanks Like M1 Abrams\\Leopard To Ukraine\n",
      "Ukraine #NATO Video Archive\n",
      "\n",
      "#Putin #RussianMobilization #Russian #Russie #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #USA\n",
      "https://t.co/S1Z4YOFibM\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575834054905462784\n",
      "tweet = üëèFootage of a Russian tank being knocked out by Ukrainian forces in Ol'hivka, Kharkiv Oblast.\n",
      "#Russian #Russia #Ukraine #Ukrainian #UkraineWar #UkraineRussiaWar #RussiaIsATerroristStateR https://t.co/YMADdnvXWQ\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"tank Kharkiv\"\n",
    "print(\"Query:\", query)\n",
    "results = w2v_score_index.search(query)\n",
    "top = 10\n",
    "\n",
    "print(\"\\n======================\\nSample of {} results out of {} for the searched query:\\n\".format(top, len(results)))\n",
    "for d_id in results[:top]:\n",
    "    print(\"tweet_id = {}\\ntweet = {}\".format(d_id, clean_df[clean_df[\"tweet_id\"]==d_id][\"tweet\"].item()))\n",
    "    print(\"\\n\\n-------------------------------------------------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
