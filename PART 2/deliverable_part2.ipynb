{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "import numpy as np\n",
    "import collections\n",
    "from numpy import linalg as la\n",
    "import time\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions and modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_json_to_dataframe(doc_path = '../data/Rus_Ukr_war_data.json'):\n",
    "    with open(doc_path) as fp:\n",
    "        lines = fp.readlines()\n",
    "    df=pd.read_json(doc_path, lines=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_raw_dataset(raw_df):\n",
    "    # Select only relevant columns\n",
    "    clean_df = raw_df[[\"created_at\",\"id_str\",\"full_text\",\"entities\",\"favorite_count\",\"retweet_count\",\"user\"]]\n",
    "\n",
    "    # Rename columns\n",
    "    renames = {\"created_at\":\"date\", \"full_text\":\"tweet\", \"favorite_count\":\"likes\",\"retweet_count\":\"retweets\", \"id_str\":\"tweet_id\"}\n",
    "    clean_df = clean_df.rename(columns=renames)\n",
    "\n",
    "    # Create Series of list of hashtags from `entities` object\n",
    "    df_hashtags = pd.json_normalize(clean_df[\"entities\"])[\"hashtags\"]\n",
    "    df_hashtags = df_hashtags.apply(lambda x: [item[\"text\"] for item in x])\n",
    "\n",
    "    # Create Series of username ids\n",
    "    df_user = pd.json_normalize(clean_df[\"user\"])[\"id\"].rename(\"user_id\")\n",
    "\n",
    "    # Merge hashtags and username columns to the DataFrame\n",
    "    clean_df = pd.concat([clean_df,df_hashtags,df_user], axis=1).drop(columns=[\"entities\",\"user\"])\n",
    "\n",
    "    # Create URL column manually from the user id and tweet id columns\n",
    "    clean_df[\"url\"] = \"https://twitter.com/\" + clean_df[\"user_id\"].astype(str) + \"/status/\" + clean_df[\"tweet_id\"].astype(str)\n",
    "\n",
    "    # Extract tags to other users from the tweet body\n",
    "    clean_df[\"tags\"] = clean_df[\"tweet\"].apply(lambda x: re.findall(r\"@(\\w+)\", x))\n",
    "\n",
    "    # Returns a DataFrame of tweets with columns [\"date\", \"tweet_id\", \"tweet\", \"likes\", \"retweets\", \"hashtags\", \"user_id\", \"url\", \"tags\", \"tags\"]\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "def remove_emojis(tweet):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emojis\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictograms\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # Flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    return emoji_pattern.sub(r'', tweet)\n",
    "\n",
    "\n",
    "def clean_tweet(line):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    ## START CODE\n",
    "    line = re.sub(r'[.,;:!?\"\\'-@]', '', line).replace(\"#\", \"\").replace(\"‚Äô\", \"\").replace(\"‚Äú\", \"\").replace(\"\\n\",\" \")\n",
    "    line =  line.lower() ## Transform in lowercase\n",
    "    line = remove_emojis(line).strip().replace(\"  \", \" \")\n",
    "    line = line.split(\" \") ## Tokenize the text to get a list of terms\n",
    "    line =[word for word in line if word not in stop_words]  ## eliminate the stopwords (HINT: use List Comprehension)\n",
    "    line =[stemmer.stem(word) for word in line] ## perform stemming (HINT: use List Comprehension)\n",
    "    line = [word for word in line if word != \"\"]\n",
    "    ## END CODE\n",
    "    \n",
    "    return line\n",
    "\n",
    "\n",
    "def process_text_column(column):\n",
    "    column = column.apply(clean_tweet)\n",
    "    return column\n",
    "\n",
    "def join_docs_tweets_dfs(tweets, csv_file='../data/Rus_Ukr_war_data_ids.csv'):\n",
    "    docs = pd.read_csv(csv_file, sep=\"\\t\", header=None)\n",
    "    docs = docs.rename(columns={0:\"doc_id\",1:\"tweet_id\"})\n",
    "    tweets = tweets.join(docs.set_index('tweet_id'), on='tweet_id')\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 3}\n"
     ]
    }
   ],
   "source": [
    "term_docs = {1, 2, 3, 4, 6}\n",
    "b = {1, 3}\n",
    "\n",
    "c = term_docs.intersection(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndex():\n",
    "\n",
    "    def __init__(self, ids, stemmed_text):\n",
    "        \n",
    "        self.index = defaultdict(list)\n",
    "\n",
    "        stemmed_text = stemmed_text.tolist()\n",
    "        ids = ids.tolist()\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "\n",
    "            tweet = stemmed_text[i]\n",
    "            tweet_id = ids[i]\n",
    "\n",
    "            terms = [word for word in tweet]\n",
    "            page_id = int(tweet_id)\n",
    "\n",
    "            current_page_index = {}\n",
    "\n",
    "            for position, term in enumerate(terms):\n",
    "                try:\n",
    "                    current_page_index[term][1].append(position)\n",
    "                except:\n",
    "                    current_page_index[term] = [page_id, array('I', [position])]\n",
    "\n",
    "            for term_page, posting_page in current_page_index.items():\n",
    "                self.index[term_page].append(posting_page)\n",
    "\n",
    "\n",
    "    def search(self, query):\n",
    "\n",
    "        query = clean_tweet(query)\n",
    "        docs = set()\n",
    "        for term in query:\n",
    "            try:\n",
    "                term_docs = [posting[0] for posting in self.index[term]]\n",
    "                term_docs = set(term_docs)\n",
    "                if len(docs)==0:\n",
    "                    docs = docs.union(term_docs)\n",
    "                else:\n",
    "                    docs = docs.intersection(term_docs)\n",
    "            except:\n",
    "                pass\n",
    "        docs = list(docs)\n",
    "        return docs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TfIdfIndex():\n",
    "\n",
    "    def __init__(self, ids, stemmed_text, num_documents):\n",
    "        \n",
    "        self.index = defaultdict(list)\n",
    "        self.tf = defaultdict(list)\n",
    "        self.df = defaultdict(int)\n",
    "        self.idf = defaultdict(float)\n",
    "\n",
    "        stemmed_text = stemmed_text.tolist()\n",
    "        ids = ids.tolist()\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "\n",
    "            tweet = stemmed_text[i]\n",
    "            tweet_id = ids[i]\n",
    "\n",
    "            terms = [word for word in tweet]\n",
    "            page_id = int(tweet_id)\n",
    "\n",
    "            current_page_index = {}\n",
    "\n",
    "            for position, term in enumerate(terms):\n",
    "                try:\n",
    "                    current_page_index[term][1].append(position)\n",
    "                except:\n",
    "                    current_page_index[term] = [page_id, array('I', [position])]\n",
    "\n",
    "            norm = 0\n",
    "            for term, posting in current_page_index.items():\n",
    "                norm += len(posting[1]) ** 2\n",
    "            norm = math.sqrt(norm)\n",
    "\n",
    "            for term, posting in current_page_index.items():\n",
    "                self.tf[term].append(np.round(len(posting[1]) / norm, 4))\n",
    "                self.df[term] += 1\n",
    "\n",
    "            for term_page, posting_page in current_page_index.items():\n",
    "                self.index[term_page].append(posting_page)\n",
    "\n",
    "            for term in self.df:\n",
    "                self.idf[term] = np.round(np.log(float(num_documents / self.df[term])), 4)\n",
    "\n",
    "\n",
    "    def rank(self, stemmed_query, unranked_results):\n",
    "                                          \n",
    "        doc_vectors = defaultdict(lambda: [0] * len(stemmed_query))\n",
    "        query_vector = [0] * len(stemmed_query)\n",
    "\n",
    "        # compute the norm for the query tf\n",
    "        query_terms_count = collections.Counter(stemmed_query)  # get the frequency of each term in the query.\n",
    "        # Example: collections.Counter([\"hello\",\"hello\",\"world\"]) --> Counter({'hello': 2, 'world': 1})\n",
    "\n",
    "        query_norm = la.norm(list(query_terms_count.values()))\n",
    "\n",
    "        for termIndex, term in enumerate(stemmed_query):  #termIndex is the index of the term in the query\n",
    "            if term not in self.index:\n",
    "                continue\n",
    "\n",
    "            # TODO: check how to vectorize the query\n",
    "            # query_vector[termIndex]=idf[term]  # original\n",
    "            ## Compute tf*idf(normalize TF as done with documents)\n",
    "            query_vector[termIndex] = query_terms_count[term] / query_norm * self.idf[term]\n",
    "\n",
    "            # Generate doc_vectors for matching docs\n",
    "            for doc_index, (doc, postings) in enumerate(self.index[term]):\n",
    "                # Example of [doc_index, (doc, postings)]\n",
    "                # 0 (26, array('I', [1, 4, 12, 15, 22, 28, 32, 43, 51, 68, 333, 337]))\n",
    "                # 1 (33, array('I', [26, 33, 57, 71, 87, 104, 109]))\n",
    "                # term is in doc 26 in positions 1,4, .....\n",
    "                # term is in doc 33 in positions 26,33, .....\n",
    "\n",
    "                #tf[term][0] will contain the tf of the term \"term\" in the doc 26\n",
    "                if doc in unranked_results:\n",
    "                    doc_vectors[doc][termIndex] = self.tf[term][doc_index] * self.idf[term] \n",
    "\n",
    "        # Calculate the score of each doc\n",
    "        # compute the cosine similarity between queyVector and each docVector:\n",
    "        # HINT: you can use the dot product because in case of normalized vectors it corresponds to the cosine similarity\n",
    "        # see np.dot\n",
    "\n",
    "        doc_scores = [[np.dot(curDocVec, query_vector), doc] for doc, curDocVec in doc_vectors.items()]\n",
    "        doc_scores.sort(reverse=True)\n",
    "        #print(doc_scores)\n",
    "        result_docs = [x[1] for x in doc_scores]\n",
    "        #print document titles instead if document id's\n",
    "        #result_docs=[ title_index[x] for x in result_docs ]\n",
    "\n",
    "        return result_docs\n",
    "                                          \n",
    "    def search(self, query):\n",
    "\n",
    "        query = clean_tweet(query)\n",
    "        docs = set()\n",
    "        for term in query:\n",
    "            try:\n",
    "                # store in term_docs the ids of the docs that contain \"term\"\n",
    "                term_docs = set([posting[0] for posting in self.index[term]])\n",
    "                                          \n",
    "                # retain all documents which contain all words from the query\n",
    "                if len(docs)==0:\n",
    "                    docs = docs.union(term_docs)\n",
    "                else:\n",
    "                    docs = docs.intersection(term_docs)\n",
    "            except:\n",
    "                #term is not in index\n",
    "                pass\n",
    "        docs = list(docs) #docs are the unranked results\n",
    "                                          \n",
    "        ranked_docs = self.rank(query, docs)\n",
    "\n",
    "        return ranked_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Tweets in the corpus: 4000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_id</th>\n",
       "      <th>url</th>\n",
       "      <th>tags</th>\n",
       "      <th>stemmed_tweet</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-30 18:39:17+00:00</td>\n",
       "      <td>1575918221013979136</td>\n",
       "      <td>@MelSimmonsFCDO Wrong. Dictator Putin's Fascis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[RussiainvadesUkraine, UkraineRussiaWar]</td>\n",
       "      <td>1404526426330701825</td>\n",
       "      <td>https://twitter.com/1404526426330701825/status...</td>\n",
       "      <td>[MelSimmonsFCDO]</td>\n",
       "      <td>[melsimmonsfcdo, wrong, dictat, putin, fascist...</td>\n",
       "      <td>doc_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-30 18:38:44+00:00</td>\n",
       "      <td>1575918081461080064</td>\n",
       "      <td>üá∫üá¶‚ù§Ô∏è The Armed Forces liberated the village of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Drobysheve, Lymansk, Donetsk, UkraineRussiaWa...</td>\n",
       "      <td>1257116113898536961</td>\n",
       "      <td>https://twitter.com/1257116113898536961/status...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[arm, forc, liber, villag, drobyshev, lymansk,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-30 18:38:23+00:00</td>\n",
       "      <td>1575917992390823936</td>\n",
       "      <td>ALERT üö®Poland preps anti-radiation tablets ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[NATO, Putin, Russia, RussiaInvadedUkraine, Uk...</td>\n",
       "      <td>1460003892415053828</td>\n",
       "      <td>https://twitter.com/1460003892415053828/status...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[alert, poland, prep, antiradi, tablet, nuclea...</td>\n",
       "      <td>doc_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-30 18:38:03+00:00</td>\n",
       "      <td>1575917907774967808</td>\n",
       "      <td>I‚Äôm still waiting for my google map üó∫Ô∏è to upda...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[Putin, UkraineRussiaWar]</td>\n",
       "      <td>285766081</td>\n",
       "      <td>https://twitter.com/285766081/status/157591790...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[im, still, wait, googl, map, updat, russia, n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-30 18:37:56+00:00</td>\n",
       "      <td>1575917878410301440</td>\n",
       "      <td>@EmmanuelMacron probably you're right or you h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[European, UkraineRussiaWar]</td>\n",
       "      <td>1537193346107686915</td>\n",
       "      <td>https://twitter.com/1537193346107686915/status...</td>\n",
       "      <td>[EmmanuelMacron]</td>\n",
       "      <td>[emmanuelmacron, probabl, your, right, say, an...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date             tweet_id  \\\n",
       "0 2022-09-30 18:39:17+00:00  1575918221013979136   \n",
       "1 2022-09-30 18:38:44+00:00  1575918081461080064   \n",
       "2 2022-09-30 18:38:23+00:00  1575917992390823936   \n",
       "3 2022-09-30 18:38:03+00:00  1575917907774967808   \n",
       "4 2022-09-30 18:37:56+00:00  1575917878410301440   \n",
       "\n",
       "                                               tweet  likes  retweets  \\\n",
       "0  @MelSimmonsFCDO Wrong. Dictator Putin's Fascis...      0         0   \n",
       "1  üá∫üá¶‚ù§Ô∏è The Armed Forces liberated the village of...      0         0   \n",
       "2  ALERT üö®Poland preps anti-radiation tablets ove...      0         0   \n",
       "3  I‚Äôm still waiting for my google map üó∫Ô∏è to upda...      0         0   \n",
       "4  @EmmanuelMacron probably you're right or you h...      0         0   \n",
       "\n",
       "                                            hashtags              user_id  \\\n",
       "0           [RussiainvadesUkraine, UkraineRussiaWar]  1404526426330701825   \n",
       "1  [Drobysheve, Lymansk, Donetsk, UkraineRussiaWa...  1257116113898536961   \n",
       "2  [NATO, Putin, Russia, RussiaInvadedUkraine, Uk...  1460003892415053828   \n",
       "3                          [Putin, UkraineRussiaWar]            285766081   \n",
       "4                       [European, UkraineRussiaWar]  1537193346107686915   \n",
       "\n",
       "                                                 url              tags  \\\n",
       "0  https://twitter.com/1404526426330701825/status...  [MelSimmonsFCDO]   \n",
       "1  https://twitter.com/1257116113898536961/status...                []   \n",
       "2  https://twitter.com/1460003892415053828/status...                []   \n",
       "3  https://twitter.com/285766081/status/157591790...                []   \n",
       "4  https://twitter.com/1537193346107686915/status...  [EmmanuelMacron]   \n",
       "\n",
       "                                       stemmed_tweet doc_id  \n",
       "0  [melsimmonsfcdo, wrong, dictat, putin, fascist...  doc_1  \n",
       "1  [arm, forc, liber, villag, drobyshev, lymansk,...    NaN  \n",
       "2  [alert, poland, prep, antiradi, tablet, nuclea...  doc_3  \n",
       "3  [im, still, wait, googl, map, updat, russia, n...    NaN  \n",
       "4  [emmanuelmacron, probabl, your, right, say, an...    NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_path = '../data/Rus_Ukr_war_data.json'\n",
    "csv_path = '../data/Rus_Ukr_war_data_ids.csv'\n",
    "\n",
    "# Import from JSON file\n",
    "raw_df = from_json_to_dataframe(doc_path)\n",
    "\n",
    "# Clean raw DataFrame to have a more convenient structure\n",
    "clean_df = clean_raw_dataset(raw_df)\n",
    "\n",
    "# \n",
    "clean_df[\"stemmed_tweet\"] = process_text_column(clean_df[\"tweet\"])\n",
    "\n",
    "\n",
    "clean_df = join_docs_tweets_dfs(clean_df, csv_path)\n",
    "\n",
    "\n",
    "print(\"Total number of Tweets in the corpus: {}\".format(len(clean_df)))\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = InvertedIndex(ids=clean_df[\"tweet_id\"], stemmed_text = clean_df[\"stemmed_tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert your query:\n",
      "\n",
      "Query: putin kill\n",
      "\n",
      "======================\n",
      "Sample of 10 results out of 17 for the searched query:\n",
      "\n",
      "tweet_id = 1575904420633939968\n",
      "tweet = #UkraineWar #Ukraine #Russia #ukrainerussiawar #Putin #SanktionengegendieUSA #MAGA #‰øÑÁΩóÊñØ #‰πåÂÖãÂÖ∞ #‰∏≠Âúã\n",
      "\n",
      "Tears in Kadyrov's eyes. After a minute of silence in memory of those killed in Donbass\n",
      "\n",
      " https://t.co/Rfjil6EHo2\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575898687808540672\n",
      "tweet = ‚ö°‚ùóOne of the Russian propagandists after Putin's statements: \n",
      "\"We will defeat everyone! We will kill everyone! We will rob everyone we want! Everything will be as we love!\"\n",
      "\n",
      "#Russia #RussiaIsANaziState #PutinWarCriminal #Russians #RussiaIsATerroristState #UkraineRussiaWar https://t.co/eBF29uF0z3\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575204700882104320\n",
      "tweet = \"Is Putin Killing Oligarchs? | 14 Suspicious Russian Deaths\n",
      "Russian-Ukraine #NATO Video Archive\n",
      "#Russia #Ukraine #Putin #Russian #RussianMobilization #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #Kherson #USA #Biden #Russians \n",
      "https://t.co/HC7qeA2Hip\n",
      "\"\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575642234258481152\n",
      "tweet = #Russia #Ukraine #RussianArmy \n",
      "Ukraine Kills 500 Russian Troops | Kadyrov Warns Russian Protesters \n",
      "\n",
      "Ukraine #NATO Video ARCHIVE .\n",
      "\n",
      "#Putin #Russian #RussianMobilization #RussiaUkraineWar #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar  #USA https://t.co/GLfQMHQzqB\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575810892209364992\n",
      "tweet = 23 killed in missile strike on Zaporizhzhia civilian convoy; #Putin to host Kremlin ceremony for annexing 4 parts of #Ukraine\n",
      "\n",
      "#RussianUkrainianWar #UkraineRussiaWar #PutinWarCrimes #VolodymyrZelensky #RussiaInvadedUkraine #Russia #PutinWarCriminal #RussiaIsANaziState #Russians https://t.co/wqjDLCOcoM\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575642411828584448\n",
      "tweet = #Russia #Ukraine #Putin \n",
      "Is Putin Killing Oligarchs? | 14 Suspicious Russian Deaths\n",
      "Russian-Ukraine #NATO Video Archive\n",
      "\n",
      "#Russian #RussianMobilization #Russians #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #Kherson #USA #Biden  \n",
      "https://t.co/HC7qezKy4h\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575233608075255808\n",
      "tweet = I think claims of genocide of ethnic Russians in Donbas could be a fake pretense for an invasion of Ukraine just as much as I think Vladimir Putin could be operating under a bribe to slowly let Ukraine kill all Russian fighters for the Zionists. #ukrainerussia #UkraineRussiaWar\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575269385475952640\n",
      "tweet = #UkraineRussiaWar #Ukraine #Russia\n",
      "\n",
      "üåê Social media\n",
      "Comment:It's not about killing russians. It's about living in a free democratic world. About the fight of Ukraine to protect its sovereignty and independency. Russians must understand that #putin is manipulating and killing them https://t.co/z4S1KFvbJg\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575458027720921088\n",
      "tweet = #Russia #Ukraine #Putin \n",
      "Is Putin Killing Oligarchs? | 14 Suspicious Russian Deaths\n",
      "Russian-Ukraine #NATO Video Archive\n",
      "\n",
      "#Russian #RussianMobilization #Russians #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #Kherson #USA #Biden  \n",
      "https://t.co/HC7qeA29sR\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id = 1575798982735204352\n",
      "tweet = LIVE: Attack on Ukraine civilian convoy kills 23 ahead of Putin annexation speech\n",
      "https://t.co/Y7B545Gy3e\n",
      "#Ukraine #ConvoyAttacked #VladimirPutin #AnnexationSpeech #UkraineRussiaWar\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Insert your query:\\n\")\n",
    "query = input()\n",
    "print(\"Query:\", query)\n",
    "results = inverted_index.search(query)\n",
    "top = 10\n",
    "\n",
    "print(\"\\n======================\\nSample of {} results out of {} for the searched query:\\n\".format(top, len(results)))\n",
    "for d_id in results[:top]:\n",
    "    print(\"tweet_id = {}\\ntweet = {}\".format(d_id, clean_df[clean_df[\"tweet_id\"]==d_id][\"tweet\"].item()))\n",
    "    print(\"\\n\\n-------------------------------------------------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute after implementing TFIDF INDEX\n",
    "\n",
    "num_tweets = len(clean_df)\n",
    "tf_idf_index = TfIdfIndex(ids=clean_df[\"tweet_id\"], stemmed_text = clean_df[\"stemmed_tweet\"], num_documents=num_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert your query (i.e.: presidents visiting Kyiv):\n",
      "\n",
      "Query: putin kill\n",
      "\n",
      "======================\n",
      "Sample of 10 results out of 17 for the searched query:\n",
      "\n",
      "tweet_id= 1575269385475952640\n",
      "tweet: #UkraineRussiaWar #Ukraine #Russia\n",
      "\n",
      "üåê Social media\n",
      "Comment:It's not about killing russians. It's about living in a free democratic world. About the fight of Ukraine to protect its sovereignty and independency. Russians must understand that #putin is manipulating and killing them https://t.co/z4S1KFvbJg\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id= 1575904420633939968\n",
      "tweet: #UkraineWar #Ukraine #Russia #ukrainerussiawar #Putin #SanktionengegendieUSA #MAGA #‰øÑÁΩóÊñØ #‰πåÂÖãÂÖ∞ #‰∏≠Âúã\n",
      "\n",
      "Tears in Kadyrov's eyes. After a minute of silence in memory of those killed in Donbass\n",
      "\n",
      " https://t.co/Rfjil6EHo2\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id= 1575798982735204352\n",
      "tweet: LIVE: Attack on Ukraine civilian convoy kills 23 ahead of Putin annexation speech\n",
      "https://t.co/Y7B545Gy3e\n",
      "#Ukraine #ConvoyAttacked #VladimirPutin #AnnexationSpeech #UkraineRussiaWar\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id= 1575810892209364992\n",
      "tweet: 23 killed in missile strike on Zaporizhzhia civilian convoy; #Putin to host Kremlin ceremony for annexing 4 parts of #Ukraine\n",
      "\n",
      "#RussianUkrainianWar #UkraineRussiaWar #PutinWarCrimes #VolodymyrZelensky #RussiaInvadedUkraine #Russia #PutinWarCriminal #RussiaIsANaziState #Russians https://t.co/wqjDLCOcoM\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id= 1575782059066691584\n",
      "tweet: Ukrainian President Volodymyr Zelensky calls Russia a \"terrorist state\" and \"bloodthirsty scum\" after strikes on a civilian convoy killed at least 25 and wounded 50 #Zelenskyy #Putin #Russia #Ukraine #UkraineRussiaWar @ZelenskyyUa\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id= 1575819548338847744\n",
      "tweet: #Russia celebrates the annexation with an extra massacre on a civilian humanitarian convoy, leaving 25 people killed and many wounded. #Putin must be happy, as well as all the Russian pigs attending the Hitler style ceremony in Moscow. #UkraineRussiaWar https://t.co/RLhkRwxEwt\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id= 1575642411828584448\n",
      "tweet: #Russia #Ukraine #Putin \n",
      "Is Putin Killing Oligarchs? | 14 Suspicious Russian Deaths\n",
      "Russian-Ukraine #NATO Video Archive\n",
      "\n",
      "#Russian #RussianMobilization #Russians #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #Kherson #USA #Biden  \n",
      "https://t.co/HC7qezKy4h\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id= 1575482098454261760\n",
      "tweet: #Russia #Ukraine #Putin \n",
      "Is Putin Killing Oligarchs? | 14 Suspicious Russian Deaths\n",
      "Russian-Ukraine #NATO Video Archive\n",
      "\n",
      "#Russian #RussianMobilization #Russians #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #Kherson #USA #Biden  \n",
      "https://t.co/HC7qeA2Hip\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id= 1575458027720921088\n",
      "tweet: #Russia #Ukraine #Putin \n",
      "Is Putin Killing Oligarchs? | 14 Suspicious Russian Deaths\n",
      "Russian-Ukraine #NATO Video Archive\n",
      "\n",
      "#Russian #RussianMobilization #Russians #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #Kherson #USA #Biden  \n",
      "https://t.co/HC7qeA29sR\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "tweet_id= 1575204700882104320\n",
      "tweet: \"Is Putin Killing Oligarchs? | 14 Suspicious Russian Deaths\n",
      "Russian-Ukraine #NATO Video Archive\n",
      "#Russia #Ukraine #Putin #Russian #RussianMobilization #Ukrainian #UkraineRussiaWar #Russland #Kharkiv #Zelensky #UkraineWar #Kherson #USA #Biden #Russians \n",
      "https://t.co/HC7qeA2Hip\n",
      "\"\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Also execute after having implemented TFIDF INDEX\n",
    "\n",
    "print(\"Insert your query:\\n\")\n",
    "query = input()\n",
    "print(\"Query:\", query)\n",
    "\n",
    "results = tf_idf_index.search(query)\n",
    "top = 10\n",
    "\n",
    "print(\"\\n======================\\nSample of {} results out of {} for the searched query:\\n\".format(top, len(results)))\n",
    "for d_id in results[:top]:\n",
    "    print(\"tweet_id= {}\\ntweet: {}\".format(d_id, clean_df[clean_df[\"tweet_id\"]==d_id][\"tweet\"].item()))\n",
    "    print(\"\\n\\n-------------------------------------------------------------------------------------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EVALUATION PART\n",
    "\n",
    "# We need to import the evaluation_gt file\n",
    "# I think it is a just a csv, so just pandas read csv\n",
    "\n",
    "# We have to do two separate evaluations\n",
    "\n",
    "# First, running the queries in the pdf (they call them information needs)\n",
    "# and then computing the P@K, R@K, etc. for the 3 queries they propose\n",
    "\n",
    "# Second, inventing two new queries, and assessing ourselves if the top N results given by \n",
    "# our algorithm are relevant (1) or not (0), and then computing P@K, R@K, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>query_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc_1452</td>\n",
       "      <td>Q3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc_2908</td>\n",
       "      <td>Q3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc_618</td>\n",
       "      <td>Q3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc_489</td>\n",
       "      <td>Q3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc_110</td>\n",
       "      <td>Q3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        doc query_id  label\n",
       "0  doc_1452       Q3      1\n",
       "1  doc_2908       Q3      1\n",
       "2   doc_618       Q3      1\n",
       "3   doc_489       Q3      1\n",
       "4   doc_110       Q3      1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df = pd.read_csv(\"../data/Evaluation_gt.csv\")\n",
    "\n",
    "evaluation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY1 = \"tank Kharkiv\" # What is the discussion regarding a tank in Kharkiv?\n",
    "QUERY2 = \"nord stream\" # What discussion are there about the Nord Stream pipeline?\n",
    "QUERY3 = \"territories annexation russia\" # What is being said about the annexation of territories in Russia?\n",
    "\n",
    "QUERY4 = \"\" # \n",
    "QUER5 = \"putin kill\" # Are there discussions or messages about killing president Putin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(doc_score, y_score, k=10): # P@K\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc_score: Ground truth (true relevance labels).\n",
    "    y_score: Predicted scores.\n",
    "    k : number of doc to consider.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "\n",
    "    \"\"\"\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    doc_score = np.take(doc_score, order[:k])\n",
    "    relevant = sum(doc_score == 1)\n",
    "    return float(relevant) / k\n",
    "\n",
    "\n",
    "def recall_at_k(): # R@K\n",
    "    pass\n",
    "\n",
    "def avg_precision_at_k(): # AP@K\n",
    "    pass\n",
    "\n",
    "def f1_score(): # F1\n",
    "    pass\n",
    "\n",
    "def mean_avg_precision(): # MAP\n",
    "    pass\n",
    "\n",
    "def mean_reciprocal_rank(): # MRR\n",
    "    pass\n",
    "\n",
    "def normalized_discounted_cumulative_gain(): # NDCG\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMING QUERY1: tank Kharkiv\n",
      "\n",
      "Using stadard Inverted Index...\n",
      "              tweet_id  predicted\n",
      "0  1575893901080027136          0\n",
      "1  1575889650471665664          1\n",
      "2  1575697002331246592          2 \n",
      "...\n",
      "\n",
      "Using TF-IDF Index...\n",
      "              tweet_id  predicted\n",
      "0  1575739143748927488          0\n",
      "1  1575528927245770752          1\n",
      "2  1575187749447307264          2 \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(\"PERFORMING QUERY1:\", QUERY1)\n",
    "\n",
    "current_query = \"Q1\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=pd.core.common.SettingWithCopyWarning)\n",
    "ground_truth = evaluation_df.loc[evaluation_df[\"query_id\"]==current_query]\n",
    "ground_truth_aux = evaluation_df.loc[(evaluation_df[\"query_id\"]!=current_query)&(evaluation_df[\"label\"]==1)]\n",
    "ground_truth_aux[\"label\"] = 0\n",
    "ground_truth = pd.concat([ground_truth, ground_truth_aux])\n",
    "warnings.filterwarnings(\"default\", category=pd.core.common.SettingWithCopyWarning)\n",
    "\n",
    "print(\"\\nUsing stadard Inverted Index...\")\n",
    "results = inverted_index.search(QUERY1)\n",
    "results = pd.DataFrame({\"tweet_id\":results, \"predicted\":range(len(results))})\n",
    "print(results.head(3), \"\\n...\")\n",
    "\n",
    "print(\"\\nUsing TF-IDF Index...\")\n",
    "results = tf_idf_index.query(QUERY1)\n",
    "results = pd.DataFrame({\"tweet_id\":results, \"predicted\":range(len(results))})\n",
    "print(results.head(3), \"\\n...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
